<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>(컴공과 왜갔지...) 클로드 오퍼스 4.6이 개발자 밥그릇 제대로 뺏으려고 작정했습ᄂ. - VidDigest</title>
    <link rel="stylesheet" href="../../css/style.css">
</head>
<body>
    <div class="header">
        <div class="header-inner">
            <a href="../../" class="site-title">VidDigest</a>
        </div>
        <h1>(컴공과 왜갔지...) 클로드 오퍼스 4.6이 개발자 밥그릇 제대로 뺏으려고 작정했습ᄂ.</h1>
        <div class="meta">
            <span></span>
            <span></span>
            <span>2026-02-06</span>
        </div>
    </div>
    <div class="container">
<p>모든 스크린샷 분석이 완료되었습니다. 이제 요약을 작성하겠습니다.</p>
<blockquote><p><strong>채널</strong>: 성공지식백과 | <strong>길이</strong>: 12:40 | <strong>날짜</strong>: 20260205</p></blockquote>
<h2>핵심 내용</h2>
<ul>
<li>Anthropic이 Claude Opus 4.6을 출시했으며, 지식 노동, 에이전트 검색, 코딩, 추리 등 모든 주요 벤치마크에서 업계 1위를 기록</li>
<li>GDPval-AA 리더보드에서 1606점으로 에이전트 하네스와 AI 챗봇 모두 통합 1위 달성</li>
<li>에이전틱 코딩(Terminal-Bench 2.0)에서 65.4%, 에이전틱 검색(BrowseComp)에서 84.0%로 압도적 성능</li>
<li>100만 토큰 컨텍스트, 128K 출력 토큰, 적응형 사고(Adaptive Thinking) 등 새로운 기능 도입</li>
<li>Claude Code를 활용한 실제 바이브 코딩 데모(체스 웹앱)를 통해 실무 코딩 능력 시연</li>
</ul>
<h2>상세 요약</h2>
<h3>Opus 4.6 출시 및 벤치마크 성능</h3>
<p>Anthropic이 클로드 Opus 4.6을 공개했습니다. 코딩뿐만 아니라 지식 노동, 에이전트 검색, 추리 등 다방면에서 최첨단 성능을 자랑합니다.</p>
<div class="screenshot-container"><img src="images/segment_000.jpg" alt="Opus 4.6 소개" loading="lazy">
<div class="caption">Opus 4.6 소개</div>
</div>
<p><strong>Knowledge Work (지식 노동)</strong> 벤치마크인 GDPval-AA에서 Opus 4.6은 Elo 점수 1606으로 1위를 기록했습니다. Opus 4.5(1416), Sonnet 4.5(1277), Gemini 3 Pro(1195), GPT-5.2(1462)를 모두 앞섰습니다.</p>
<div class="screenshot-container"><img src="images/segment_001.jpg" alt="Knowledge Work 벤치마크" loading="lazy">
<div class="caption">Knowledge Work 벤치마크</div>
</div>
<p>GDPval-AA 리더보드 전체에서도 에이전트 하네스와 AI 챗봇 두 가지로 나뉘어 비교했을 때, Opus 4.6이 1606점으로 압도적 1위이며, GPT-5.2(xhigh)가 1579점, GPT-5.2(medium)가 1462점으로 뒤를 잇고 있습니다.</p>
<div class="screenshot-container"><img src="images/segment_003.jpg" alt="GDPval-AA 리더보드 전체" loading="lazy">
<div class="caption">GDPval-AA 리더보드 전체</div>
</div>
<h3>추리 및 코딩 벤치마크</h3>
<p><strong>Multidisciplinary Reasoning (Humanity&#x27;s Last Exam)</strong> 에서 Opus 4.6은 도구 없이 40.0%, 도구 사용 시 53.1%를 기록했습니다. GPT-5.2 Pro가 도구 사용 시 50.0%인 것과 비교하면 도구 활용 시 최고 성능입니다.</p>
<div class="screenshot-container"><img src="images/segment_006.jpg" alt="추리 벤치마크" loading="lazy">
<div class="caption">추리 벤치마크</div>
</div>
<p><strong>Agentic Coding (Terminal-Bench 2.0)</strong> 에서는 65.4%로 최고 점수를 기록했습니다. Opus 4.5(59.8%), Sonnet 4.5(51.0%), Gemini 3 Pro(56.2%), GPT-5.2-codex(64.7%)를 넘어서며, 에이전틱 코딩 분야에서 코딩 흐름 자체를 평가하는 수치가 가장 높습니다.</p>
<div class="screenshot-container"><img src="images/segment_007.jpg" alt="에이전틱 코딩 벤치마크" loading="lazy">
<div class="caption">에이전틱 코딩 벤치마크</div>
</div>
<p><strong>Agentic Search (BrowseComp)</strong> 에서는 84.0%를 기록하여, Opus 4.5(67.8%), Sonnet 4.5(43.9%), Gemini Deep Research(59.2%), GPT-5.2 Pro(77.9%)를 크게 앞서며 실무에서도 중요한 벤치마크에서 압도적 성능을 보여주었습니다.</p>
<div class="screenshot-container"><img src="images/segment_009.jpg" alt="에이전틱 검색 벤치마크" loading="lazy">
<div class="caption">에이전틱 검색 벤치마크</div>
</div>
<h3>장문맥(Long-context) 성능의 혁신</h3>
<p><strong>Long-context Reasoning (Graphwalks)</strong> 에서 Opus 4.6 Parents 1M이 72.0점으로 100점에 가까워지고 있으며, 기존 Sonnet 4.5는 Parents 1M에서 50.2점, BFS 1M에서 25.6점에 불과했습니다.</p>
<div class="screenshot-container"><img src="images/segment_011.jpg" alt="장기적 맥락 추론" loading="lazy">
<div class="caption">장기적 맥락 추론</div>
</div>
<p><strong>Long-context Retrieval (MRCR v2 8-needle)</strong> 에서는 Opus 4.6 256k가 93.0%, 1M이 76.0%를 기록한 반면, Sonnet 4.5는 256k에서 10.8%, 1M에서 18.5%에 그쳤습니다. 기존 모델에서 맥락을 잃어버리는 &quot;컨텍스트 부패&quot; 문제를 Opus 4.6이 획기적으로 해결했습니다.</p>
<div class="screenshot-container"><img src="images/segment_012.jpg" alt="장문맥 검색 성능" loading="lazy">
<div class="caption">장문맥 검색 성능</div>
</div>
<h3>새로운 기능들 - 개발자 플랫폼</h3>
<p>Anthropic은 Opus 4.6과 함께 다양한 새로운 기능을 도입했습니다:</p>
<ul>
<li><strong>적응형 사고(Adaptive Thinking)</strong>: 확장적 사고를 활성화/비활성화하는 이진 선택이 아닌, Claude가 심층적인 추론이 필요한 시점을 스스로 판단</li>
<li><strong>노력 수준(Effort)</strong>: 낮음, 중간, 높음(기본값), 최대 네 가지 레벨로 프로젝트의 복잡도에 따라 조절 가능</li>
<li><strong>컨텍스트 압축(베타)</strong>: 장시간 대화와 에이전트 작업 시 컨텍스트 창에 도달하면 자동으로 요약하여 시간 제한 없이 작업 수행 가능</li>
<li><strong>100만 토큰 컨텍스트(베타)</strong>: Opus급 최초의 100만 토큰 컨텍스트 모델 (20만 토큰 초과 시 프리미엄 가격 적용: 입력 $10/출력 $37.50 per MTok)</li>
<li><strong>128,000개의 출력 토큰</strong>: 대규모 출력 작업을 여러 요청으로 나누지 않고 완료 가능</li>
</ul>
<div class="screenshot-container"><img src="images/segment_017.jpg" alt="개발자 플랫폼 새 기능" loading="lazy">
<div class="caption">개발자 플랫폼 새 기능</div>
</div>
<h3>Claude Code 에이전트 팀 기능</h3>
<p>Claude Code에서 이제 에이전트 팀을 구성하여 작업을 함께 수행할 수 있습니다. 여러 Claude Code 인스턴스가 팀으로 협력하여 작업을 공유하고, 에이전트 간 메시징을 사용하며, 중앙 집중식으로 관리할 수 있습니다. 하위 에이전트를 생성해서 병렬 작업도 가능합니다.</p>
<div class="screenshot-container"><img src="images/segment_014.jpg" alt="에이전트 팀 기능" loading="lazy">
<div class="caption">에이전트 팀 기능</div>
</div>
<h3>가격 정책</h3>
<p>Claude 요금제는 세 가지입니다:</p>
<ul>
<li><strong>Free</strong>: $0 - 무료 체험</li>
<li><strong>Pro</strong>: $17/월 (연간 구독 시, 월 결제 시 $20) - 일상적인 생산성 향상</li>
<li><strong>Max</strong>: $100부터 - Pro 대비 5x 또는 20x 사용량</li>
</ul>
<p>API 가격의 경우 Opus 4.6은:</p>
<ul>
<li>Input: 200K 토큰 이하 $5/MTok, 200K 초과 $10/MTok</li>
<li>Output: 200K 이하 $25/MTok, 200K 초과 $37.50/MTok</li>
</ul>
<p>비교적으로 Sonnet 4.5는 Input $3/$6, Output $15이며, Haiku 4.5는 Input $1, Output $5로 가장 저렴합니다.</p>
<div class="screenshot-container"><img src="images/segment_021.jpg" alt="API 가격 비교" loading="lazy">
<div class="caption">API 가격 비교</div>
</div>
<h3>실제 바이브 코딩 데모 - 체스 웹앱</h3>
<p>영상에서는 Claude Code v2.1.32 (Opus 4.6, Claude Max)를 사용하여 실제 체스 웹앱을 바이브 코딩으로 만드는 과정을 시연합니다. &quot;체스 웹앱을 만들겠습니다. 완전한 체스 엔진과 모던한 UI를 구현합니다&quot;라는 프롬프트로 시작하여:</p>
<ol>
<li>HTML, CSS, JavaScript 파일을 자동 생성 (index.html 90줄, style.css 660줄)</li>
<li>사운드 효과와 무브 애니메이션을 추가하여 프로페셔널하게 완성</li>
<li>약 2분 24초만에 완전한 체스 웹앱 생성 완료</li>
</ol>
<div class="screenshot-container"><img src="images/segment_023.jpg" alt="체스 웹앱 코드 생성" loading="lazy">
<div class="caption">체스 웹앱 코드 생성</div>
</div>
<p>완성된 체스 앱은 vs AI 모드, 난이도 설정(Hard), 타이머, 기보 기록, New Game/Undo/Flip Board 등의 기능을 갖추고 있으며, 알고리즘이 확실하게 작동하는 것이 확인됩니다.</p>
<div class="screenshot-container"><img src="images/segment_027.jpg" alt="완성된 체스 웹앱" loading="lazy">
<div class="caption">완성된 체스 웹앱</div>
</div>
<h3>추가 제품 업데이트</h3>
<p>Anthropic은 Excel용 Claude를 대폭 업그레이드했으며, PowerPoint용 Claude를 연구용 미리보기 버전으로 출시했습니다. 이를 통해 Claude는 일상적인 업무에 훨씬 더 유용한 도구가 되었습니다. 또한 Visual reasoning(MMMU Pro)에서 77.3%, Multilingual Q&amp;A(MMMLU)에서 91.1% 등 다양한 벤치마크에서도 높은 성능을 보여주고 있습니다.</p>
<div class="screenshot-container"><img src="images/segment_029.jpg" alt="추가 벤치마크 및 업데이트" loading="lazy">
<div class="caption">추가 벤치마크 및 업데이트</div>
</div>
<h2>결론</h2>
<p>Claude Opus 4.6은 코딩, 지식 노동, 에이전트 검색, 추리, 장문맥 처리 등 사실상 모든 주요 AI 벤치마크에서 GPT-5.2, Gemini 3 Pro 등 경쟁 모델을 제치고 1위를 기록하며 출시되었습니다. 특히 에이전틱 코딩과 장문맥 성능에서의 도약은 기존 모델들과 차원이 다른 수준이며, Claude Code를 통한 바이브 코딩 시연에서 2분여 만에 완전한 체스 웹앱을 만들어내는 모습은 AI 코딩 능력의 현주소를 보여줍니다. 영상 제목처럼 &quot;컴공과 왜 갔지&quot;라는 자조적 반응이 나올 만큼, AI가 개발자의 영역을 빠르게 잠식하고 있다는 메시지를 강하게 전달하고 있습니다.</p>
        <div class="footer">
            Generated by VidDigest
        </div>
    </div>
    <div class="lightbox" id="lightbox" onclick="this.classList.remove('active')">
        <img id="lightbox-img" src="" alt="">
    </div>
    <script src="../../js/main.js"></script>
</body>
</html>